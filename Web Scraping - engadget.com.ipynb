{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve article urls\n",
    "\n",
    "The method below is a \"generator\" method, which can be used to generate urls for a specific topic. \n",
    "\n",
    "If you want to use it to generate urls, first create a generator method object, and then pass this obejcet to the `next` method each time you want a new url:\n",
    "\n",
    "    gen = article_url_generator(\"some topic\")\n",
    "    article_url = next(gen)\n",
    "    \n",
    "Alternatively, you can loop over all article urls like this:\n",
    "\n",
    "    for article_url in article_url_generator():\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.engadget.com/2017/03/30/toyota-research-ai-battery-material-hunt/\n",
      "https://www.engadget.com/2017/03/29/samsungs-bixby-ai-assistant-can-see-as-well-as-talk/\n"
     ]
    }
   ],
   "source": [
    "def article_url_generator(tag, max_count=None):\n",
    "    base_url = \"https://www.engadget.com\"\n",
    "    page = 1\n",
    "    while 1:\n",
    "        url = base_url + \"/tag/{}/page/{}/\".format(tag, page)\n",
    "        soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "        \n",
    "        # This is the top article - treat it differently\n",
    "        article = soup.find(\"article\")\n",
    "        if article:\n",
    "            article_url_tag = article.find(\"a\")\n",
    "            if article_url_tag is not None:\n",
    "                yield base_url + article_url_tag['href']\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # All other article url's are found using this approach\n",
    "        for article_url_tag in soup.find_all(\"a\", class_=\"o-hit__link\"):\n",
    "            yield base_url + article_url_tag['href']\n",
    "            \n",
    "        # Move to the next page\n",
    "        page += 1\n",
    "        \n",
    "gen = article_url_generator(\"ai\")\n",
    "print(next(gen))\n",
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.engadget.com/2017/03/30/toyota-research-ai-battery-material-hunt/',\n",
       " 'https://www.engadget.com/2017/03/29/samsungs-bixby-ai-assistant-can-see-as-well-as-talk/',\n",
       " 'https://www.engadget.com/2017/03/27/spotify-acquires-mightytv/',\n",
       " 'https://www.engadget.com/2017/03/27/post-intelligence-ai-social-media-coach/',\n",
       " 'https://www.engadget.com/2017/03/26/black-box-strategy-helps-neural-networks/',\n",
       " 'https://www.engadget.com/2017/03/25/recommended-reading-radioheads-ok-computer-predicted-the-fut/',\n",
       " 'https://www.engadget.com/2017/03/24/treasury-secretary-AI-job-loss/',\n",
       " 'https://www.engadget.com/2017/03/24/youtube-automates-sound-effect-captions-with-ai/',\n",
       " 'https://www.engadget.com/2017/03/24/experimental-music-video-changes-every-time-you-play-it/',\n",
       " 'https://www.engadget.com/2017/03/21/arm-DynamIQ-cortex-a9-ai-machine-learning/',\n",
       " 'https://www.engadget.com/2017/03/16/party-bot-decides-whos-on-the-guest-list/',\n",
       " 'https://www.engadget.com/2017/03/16/the-us-navy-wants-gamers-to-stop-the-rise-of-the-machines/',\n",
       " 'https://www.engadget.com/2017/03/16/scientists-want-to-define-just-how-smart-robot-surgeons-are/',\n",
       " 'https://www.engadget.com/2017/03/15/googles-ai-gets-human-help-to-avoid-offensive-search-results/',\n",
       " 'https://www.engadget.com/2017/03/14/deepmind-ai-learns-to-remember-previous-knowledge/',\n",
       " 'https://www.engadget.com/2017/03/13/baidu-ai-transcription/',\n",
       " 'https://www.engadget.com/2017/03/09/baidu-deep-voice-natural-sounding-speec/',\n",
       " 'https://www.engadget.com/2017/03/07/nvidia-launches-jetson-tx2-platform-for-drones-and-robots/',\n",
       " 'https://www.engadget.com/2017/03/07/amazon-hands-over-alexa-data-after-murder-suspect-gives-the-okay/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_article_urls(tag, num_pages):\n",
    "    urls = []\n",
    "    base_url = \"https://www.engadget.com\"\n",
    "    for page in range(1, num_pages+1):\n",
    "        url = base_url + \"/tag/{}/page/{}/\".format(tag, page)\n",
    "        soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "        \n",
    "        # This is the top article - treat it differently\n",
    "        article = soup.find(\"article\")\n",
    "        if article:\n",
    "            article_url_tag = article.find(\"a\")\n",
    "            if article_url_tag is not None:\n",
    "                urls.append(base_url + article_url_tag['href'])\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # All other article url's are found using this approach\n",
    "        for article_url_tag in soup.find_all(\"a\", class_=\"o-hit__link\"):\n",
    "            urls.append(base_url + article_url_tag['href'])\n",
    "            \n",
    "    return urls\n",
    "\n",
    "get_article_urls(\"ai\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the article body\n",
    "\n",
    "The following method is used to extract the article body from the BeautifulSoup-object (`soup`). Note that each part of the body may have substrings, so this is why we need to iterate through all the `strings` of the body elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_article_body(soup):\n",
    "    body = \"\"\n",
    "    for article_text in soup.find_all(\"div\", class_=re.compile(\"article-text\")):\n",
    "        for paragraph in article_text.find_all(\"p\"):\n",
    "            for s in paragraph.strings:\n",
    "                body += \" \" + s\n",
    "    body = re.sub(\" (?=[.!?])\", \"\", body)\n",
    "    body = \" \".join(body.split())\n",
    "    return body.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving an article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When retrieving an article, we want the following:\n",
    "- The **title** of the article\n",
    "- The **preamble** (introduction) of the article\n",
    "- The **body** (main part) of the article\n",
    "- The **author** of the article\n",
    "- The **time** the article was published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_article(url):\n",
    "    soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "    article = {}\n",
    "    \n",
    "    # Get the title of the article\n",
    "    article[\"title\"] = soup.title.get_text()\n",
    "    \n",
    "    # Get the preamble of the article\n",
    "    try:\n",
    "        article[\"preamble\"] = soup.find(\"div\", class_=re.compile(\"t-d7@m-\")).get_text().strip()\n",
    "    except AttributeError:\n",
    "        article[\"preamble\"] = \"\"\n",
    "    \n",
    "    # Get the body of the article\n",
    "    article[\"body\"] = extract_article_body(soup)\n",
    "    \n",
    "    # Get the author of the article\n",
    "    article[\"author\"] = soup.find(\"meta\", {\"name\": \"blogger_name\"}).get(\"content\")\n",
    "    \n",
    "    # Publish time\n",
    "    article[\"time\"] = soup.find(\"meta\", {\"name\": \"published_at\"}).get(\"content\")\n",
    "        \n",
    "    return article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve articles for some topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving 100 articles for topic 'ai'\n",
      "Retrieving 100 articles for topic 'gaming'\n",
      "Retrieving 100 articles for topic 'vr'\n"
     ]
    }
   ],
   "source": [
    "num_per_topic = 100\n",
    "articles = []\n",
    "topics = [\"ai\", \"gaming\", \"vr\"]\n",
    "for topic in topics:\n",
    "    url_gen = article_url_generator(topic)\n",
    "    print(\"Retrieving {} articles for topic '{}'\".format(num_per_topic, topic))\n",
    "    for i in range(num_per_topic):\n",
    "        try:\n",
    "            article = get_article(next(url_gen))\n",
    "        except StopIteration:\n",
    "            break\n",
    "        article[\"topic\"] = topic\n",
    "        articles.append(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "    \n",
    "with open(os.path.join(\"data\", \"engadget_articles.csv\"), 'w', encoding='utf-8') as csvfile:\n",
    "    columns = [\"author\", \"preamble\", \"time\", \"title\", \"body\", \"topic\"]\n",
    "    csv_writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "    csv_writer.writeheader()\n",
    "    for row in articles:\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/engadget_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - average number of words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>2064.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming</th>\n",
       "      <td>2334.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vr</th>\n",
       "      <td>1994.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_words\n",
       "topic            \n",
       "ai        2064.14\n",
       "gaming    2334.31\n",
       "vr        1994.01"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"num_words\"] = df[\"body\"].apply(len)\n",
    "pd.pivot_table(data=df, values=[\"num_words\"], index=[\"topic\"], aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - which topics has the authors written about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topic</th>\n",
       "      <th>ai</th>\n",
       "      <th>gaming</th>\n",
       "      <th>vr</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aaron Souppouris</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amber Bouman</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew Dalton</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew Tarantola</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autoblog</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "topic             ai  gaming  vr  All\n",
       "author                               \n",
       "Aaron Souppouris   2       0   1    3\n",
       "Amber Bouman       1       0   0    1\n",
       "Andrew Dalton      2       1   2    5\n",
       "Andrew Tarantola   3       2   2    7\n",
       "Autoblog           1       0   0    1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df[\"author\"], df[\"topic\"], margins=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - sort articles by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>preamble</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>topic</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jon Fingas</td>\n",
       "      <td>It should be less racist this time around.</td>\n",
       "      <td>2016-12-05T15:55:00-05:00</td>\n",
       "      <td>Microsoft's second try at social chat bots arr...</td>\n",
       "      <td>Microsoft's first foray into social chat bots ...</td>\n",
       "      <td>ai</td>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Autoblog</td>\n",
       "      <td>This could be really cool, or quite unsettling.</td>\n",
       "      <td>2016-12-05T21:37:00-05:00</td>\n",
       "      <td>Honda's NeuV concept fires up its 'emotion eng...</td>\n",
       "      <td>Enthusiasts frequently talk about cars as thou...</td>\n",
       "      <td>ai</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Jon Fingas</td>\n",
       "      <td>The frequently secretive company is opening up...</td>\n",
       "      <td>2016-12-06T15:09:00-05:00</td>\n",
       "      <td>Apple will publish its AI research</td>\n",
       "      <td>Apple isn't exactly known for sharing its rese...</td>\n",
       "      <td>ai</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Jon Fingas</td>\n",
       "      <td>The question is: could it and should it have i...</td>\n",
       "      <td>2016-12-07T17:00:00-05:00</td>\n",
       "      <td>Facebook patent hints at an automated solution...</td>\n",
       "      <td>Facebook may have said that it's stepping up i...</td>\n",
       "      <td>ai</td>\n",
       "      <td>2109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Matt Brian</td>\n",
       "      <td>The physical home button may also be replaced ...</td>\n",
       "      <td>2016-12-08T06:25:00-05:00</td>\n",
       "      <td>Samsung's Galaxy S8 might have a true edge-to-...</td>\n",
       "      <td>With the Galaxy Note 7 debacle weighing heavy ...</td>\n",
       "      <td>ai</td>\n",
       "      <td>1724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                           preamble  \\\n",
       "99  Jon Fingas         It should be less racist this time around.   \n",
       "98    Autoblog    This could be really cool, or quite unsettling.   \n",
       "97  Jon Fingas  The frequently secretive company is opening up...   \n",
       "96  Jon Fingas  The question is: could it and should it have i...   \n",
       "95  Matt Brian  The physical home button may also be replaced ...   \n",
       "\n",
       "                         time  \\\n",
       "99  2016-12-05T15:55:00-05:00   \n",
       "98  2016-12-05T21:37:00-05:00   \n",
       "97  2016-12-06T15:09:00-05:00   \n",
       "96  2016-12-07T17:00:00-05:00   \n",
       "95  2016-12-08T06:25:00-05:00   \n",
       "\n",
       "                                                title  \\\n",
       "99  Microsoft's second try at social chat bots arr...   \n",
       "98  Honda's NeuV concept fires up its 'emotion eng...   \n",
       "97                 Apple will publish its AI research   \n",
       "96  Facebook patent hints at an automated solution...   \n",
       "95  Samsung's Galaxy S8 might have a true edge-to-...   \n",
       "\n",
       "                                                 body topic  num_words  \n",
       "99  Microsoft's first foray into social chat bots ...    ai       1449  \n",
       "98  Enthusiasts frequently talk about cars as thou...    ai       1790  \n",
       "97  Apple isn't exactly known for sharing its rese...    ai       1212  \n",
       "96  Facebook may have said that it's stepping up i...    ai       2109  \n",
       "95  With the Galaxy Note 7 debacle weighing heavy ...    ai       1724  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values([\"time\"], ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More cool pandas functions can be found [here](https://www.analyticsvidhya.com/blog/2016/01/12-pandas-techniques-python-data-manipulation/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
